DETEKSI PENYAKIT JANTUNG

Kelompok : Muhamad Anwar Sanusi (2306016)
           Taslim Nuralim (2306032)

INSTALASI DAN IMPORT LIBRARY
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Kolom yang tidak logis jika bernilai 0
columns_with_zeros = ['trestbps', 'chol', 'thalach', 'oldpeak']

# Buat salinan dan ubah 0 menjadi NaN
df_copy = df.copy()
for col in columns_with_zeros:
    df_copy[col] = df_copy[col].replace(0, np.nan)

# Hitung jumlah dan persentase missing
missing_counts = df_copy.isnull().sum()
missing_percentages = (missing_counts / len(df_copy)) * 100

# Buat DataFrame dari hasil missing
missing_data = pd.DataFrame({
    'Variable': missing_counts.index,
    'Missing_Count': missing_counts.values,
    'Missing_Percentage': missing_percentages.values
})

# Ambil hanya yang ada missing-nya
missing_data = missing_data[missing_data['Missing_Count'] > 0]
# Setting untuk visualisasi
plt.style.use('default')
sns.set_palette("husl")
1. LOADING DAN PEMBACAAN DATA
Data Gathering: Memuat dataset yang diambil dari kaggle
from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
df = pd.read_csv("/content/drive/MyDrive/2306016/TB AI/heart.csv")
data = pd.read_csv("/content/drive/MyDrive/2306016/TB AI/heart.csv")
print("Dataset berhasil dimuat. Dimensi dataset:", data.shape)
print(data.head())
# Tampilkan informasi umum dataset (sesuai Gbr. 2 dalam jurnal)
print(f"Jumlah data: {data.shape[0]} pasien")
print(f"Jumlah variabel: {data.shape[1]} (8 independen + 1 dependen)")
print(f"Tipe data:")
print(data.info())
print("\nSample data (5 teratas):")
print(data.head())
2. ANALISIS EKSPLORASI DATA
# Matriks korelasi (sesuai Gbr. 3 dalam jurnal)
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 8))
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5)
plt.title('Matriks Korelasi Antar Variabel')
plt.tight_layout()
plt.show()
print("Korelasi variabel dengan Target (target):")
target_corr = correlation_matrix['target'].sort_values(ascending=False)
print(target_corr)
# === Distribusi Plot untuk Masing-Masing Variabel ===
import matplotlib.pyplot as plt

fig, axes = plt.subplots(3, 5, figsize=(20, 12))  # Sesuaikan grid dengan jumlah kolom
axes = axes.ravel()

for i, column in enumerate(df.columns):
    axes[i].hist(df[column], bins=30, edgecolor='black', alpha=0.7)
    axes[i].set_title(f'Distribusi {column}')
    axes[i].set_xlabel(column)
    axes[i].set_ylabel('Frekuensi')

plt.tight_layout()
plt.show()

3. DATA PREPROCESSING
1) Missing Value Analysis

print("Missing Value Analysis:")

# Identifikasi nilai 0 yang seharusnya missing (untuk data penyakit jantung)
columns_with_zeros = ['trestbps', 'chol', 'thalach', 'oldpeak']

import numpy as np
df_copy = df.copy()

# Ganti nilai 0 dengan NaN untuk kolom yang secara medis tidak mungkin bernilai 0
for col in columns_with_zeros:
    df_copy[col] = df_copy[col].replace(0, np.nan)

# Hitung missing values
missing_counts = df_copy.isnull().sum()
missing_percentages = (missing_counts / len(df_copy)) * 100

print("Jumlah dan persentase missing values:")
for col in missing_counts.index:
    if missing_counts[col] > 0:
        print(f"{col}: {missing_counts[col]} ({missing_percentages[col]:.2f}%)")

# Visualisasi missing values
import matplotlib.pyplot as plt
import pandas as pd

plt.figure(figsize=(10, 6))

# Buat DataFrame dari hasil missing value analysis
missing_data = pd.DataFrame({
    'Variabel': missing_counts.index,
    'Missing_Count': missing_counts.values,
    'Missing_Percentage': missing_percentages.values
})

# Ambil hanya variabel yang memiliki missing value
missing_data = missing_data[missing_data['Missing_Count'] > 0]

# Plot jika ada missing value
if not missing_data.empty:
    plt.subplot(1, 2, 1)
    plt.bar(missing_data['Variabel'], missing_data['Missing_Count'], color='salmon')
    plt.title('Jumlah Missing Values')
    plt.xticks(rotation=45)
    plt.ylabel('Jumlah')

    plt.subplot(1, 2, 2)
    plt.bar(missing_data['Variabel'], missing_data['Missing_Percentage'], color='skyblue')
    plt.title('Persentase Missing Values')
    plt.xticks(rotation=45)
    plt.ylabel('Persentase (%)')

    plt.tight_layout()
    plt.show()
else:
    print("Tidak ada missing value yang perlu divisualisasikan.")

print("\nJumlah missing value setelah penggantian 0:")
print(df_copy.isnull().sum())
print("\nMengisi missing value dengan median masing-masing kolom...")
for col in columns_with_zeros:
    median_value = df_copy[col].median()
    df_copy[col].fillna(median_value, inplace=True)
    print(f"{col} diisi dengan median: {median_value}")

print("\nNormalisasi fitur...")
X = df_copy.drop("target", axis=1)
y = df_copy["target"]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# === 2) Visualisasi Missing Value Setelah Diisi ===

# Hitung ulang missing values setelah pengisian
missing_counts_after = df_copy.isnull().sum()

print("\nMissing Value Analysis Setelah Pengisian:")
for col in missing_counts_after.index:
    if missing_counts_after[col] > 0:
        print(f"{col}: {missing_counts_after[col]} ({missing_percentages[col]:.2f}%)")

# Visualisasi: sebelum vs sesudah pengisian
import matplotlib.pyplot as plt
import pandas as pd

plt.figure(figsize=(12, 6))

# Data untuk visualisasi
missing_data_before = pd.DataFrame({
    'Variabel': missing_counts.index,
    'Jumlah Missing Before': missing_counts.values
}).set_index('Variabel')

missing_data_after = pd.DataFrame({
    'Variabel': missing_counts_after.index,
    'Jumlah Missing After': missing_counts_after.values
}).set_index('Variabel')

# Gabungkan data sebelum dan sesudah
combined_missing_data = (
    missing_data_before[missing_data_before['Jumlah Missing Before'] > 0]
    .join(missing_data_after)
)

# Plot hanya jika memang ada missing sebelumnya
if not combined_missing_data.empty:
    combined_missing_data[['Jumlah Missing Before', 'Jumlah Missing After']].plot(
        kind='bar', figsize=(10, 6), color=['salmon', 'skyblue']
    )
    plt.title('Jumlah Missing Values Sebelum dan Sesudah Pengisian dengan Median')
    plt.xlabel('Variabel')
    plt.ylabel('Jumlah Missing Values')
    plt.xticks(rotation=45, ha='right')
    plt.legend(['Sebelum Pengisian', 'Sesudah Pengisian'])
    plt.tight_layout()
    plt.show()
else:
    print("Tidak ada missing value yang terdeteksi sebelum atau sesudah pengisian.")

# Tampilkan info dan verifikasi akhir
print("\nInformasi dataset setelah pengisian missing values:")
print(df_copy.info())

print("\nJumlah missing values setelah pengisian:")
print(df_copy.isnull().sum())

# Update dataframe utama
df = df_copy.copy()
# Scatter plot Age vs Chol (meniru Gambar 6 pada jurnal diabetes, tapi untuk penyakit jantung)
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
colors = ['blue', 'red']
labels = ['Tidak Sakit Jantung', 'Sakit Jantung']

# Plot berdasarkan nilai target: 0 = tidak sakit, 1 = sakit
for i, target in enumerate([0, 1]):
    subset = df[df['target'] == target]
    plt.scatter(subset['age'], subset['chol'],
                c=colors[i], label=labels[i], alpha=0.6)

plt.xlabel('Usia (Tahun)')
plt.ylabel('Kolesterol (mg/dL)')
plt.title('Scatter Plot: Hubungan Usia dan Kolesterol terhadap Risiko Penyakit Jantung')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

Data Tidak Seimbang
print("\nAnalisis Data Tidak Seimbang:")

target_counts = df['target'].value_counts()
target_percentages = df['target'].value_counts(normalize=True) * 100

print(f"Tidak Sakit Jantung (0): {target_counts.get(0, 0)} ({target_percentages.get(0, 0):.1f}%)")
print(f"Sakit Jantung (1): {target_counts.get(1, 0)} ({target_percentages.get(1, 0):.1f}%)")

import matplotlib.pyplot as plt
# Hitung distribusi target
target_counts = df['target'].value_counts()

# Visualisasi distribusi target
plt.figure(figsize=(10, 5))

# Bar chart
plt.subplot(1, 2, 1)
plt.bar(['Tidak Sakit Jantung', 'Sakit Jantung'], target_counts.values,
        color=['skyblue', 'lightcoral'])
plt.title('Distribusi Target (Jumlah)')
plt.ylabel('Jumlah Pasien')

# Pie chart
plt.subplot(1, 2, 2)
plt.pie(target_counts.values, labels=['Tidak Sakit Jantung', 'Sakit Jantung'],
        autopct='%1.1f%%', colors=['skyblue', 'lightcoral'])
plt.title('Distribusi Target (Persentase)')

plt.tight_layout()
plt.show()
4. PEMBAGIAN DATA DAN NORMALISASI
from sklearn.model_selection import train_test_split

# Pisahkan fitur dan target
X = df.drop('target', axis=1)
y = df['target']

# Split data 70:30 (seperti di jurnal)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"Data training: {X_train.shape[0]} samples")
print(f"Data testing: {X_test.shape[0]} samples")

columns_with_zeros = ['trestbps', 'chol', 'thalach', 'oldpeak']

# Ganti 0 dengan NaN di X_train dan X_test
for col in columns_with_zeros:
    X_train[col] = X_train[col].replace(0, np.nan)
    X_test[col] = X_test[col].replace(0, np.nan)

for col in columns_with_zeros:
    median = X_train[col].median()
    X_train[col].fillna(median, inplace=True)
    X_test[col].fillna(median, inplace=True)

from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# Normalisasi
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SMOTE
print("\nMenerapkan SMOTE untuk mengatasi data tidak seimbang...")
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# Cek distribusi setelah SMOTE
print(f"Sebelum SMOTE - Sakit Jantung: {sum(y_train)} | Tidak Sakit: {len(y_train) - sum(y_train)}")
print(f"Setelah SMOTE - Sakit Jantung: {sum(y_train_balanced)} | Tidak Sakit: {len(y_train_balanced) - sum(y_train_balanced)}")

print("Cek NaN X_train:", np.isnan(X_train_scaled).sum())
# Gabungkan fitur dan target hasil SMOTE ke dalam DataFrame untuk visualisasi
data_balanced = pd.DataFrame(X_train_balanced, columns=X.columns)
data_balanced['target'] = y_train_balanced

# Bar plot untuk kolom 'target'
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 4))
sns.countplot(x="target", hue="target", data=data_balanced, palette="Set2")
plt.title("Distribusi Status Target Setelah SMOTE")
plt.xlabel("Target (0 = Tidak Sakit Jantung, 1 = Sakit Jantung)")
plt.ylabel("Jumlah")
plt.show()

print("\nAnalisis Outlier:")

# Gunakan semua kolom numerik kecuali kolom target
numerical_cols = df.drop('target', axis=1).columns  # df adalah DataFrame utama

# Buat boxplot untuk setiap fitur numerik
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(3, 5, i + 1)  # Ada 13 fitur, 3 baris x 5 kolom cukup
    sns.boxplot(y=df[col])
    plt.title(f'Boxplot dari {col}')
    plt.ylabel(col)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Fungsi untuk mendeteksi outlier dengan IQR
def detect_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers

# Kolom numerik utama yang akan dicek outlier-nya
outlier_cols_check = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca', 'thal']

print("\nMendeteksi dan menangani Outlier (menggunakan IQR):")
df_no_outlier = df.copy()  # Salin dataset asli

# Identifikasi outlier di setiap kolom
outliers_summary = {}
for col in outlier_cols_check:
    outliers = detect_outliers_iqr(df_no_outlier, col)
    outliers_summary[col] = len(outliers)
    print(f"Jumlah outlier pada kolom '{col}': {len(outliers)}")

# Visualisasi jumlah outlier per kolom
if sum(outliers_summary.values()) > 0:
    plt.figure(figsize=(10, 6))
    plt.bar(outliers_summary.keys(), outliers_summary.values(), color='coral')
    plt.title('Jumlah Outlier per Variabel (Sebelum Penanganan)')
    plt.xlabel('Variabel')
    plt.ylabel('Jumlah Outlier')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()
else:
    print("Tidak ada outlier yang terdeteksi.")

# Penanganan Outlier: Capping menggunakan batas IQR
print("\nMenangani outlier dengan mengganti nilainya menggunakan batas IQR...")

for col in outlier_cols_check:
    Q1 = df_no_outlier[col].quantile(0.25)
    Q3 = df_no_outlier[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df_no_outlier[col] = np.where(df_no_outlier[col] < lower_bound, lower_bound, df_no_outlier[col])
    df_no_outlier[col] = np.where(df_no_outlier[col] > upper_bound, upper_bound, df_no_outlier[col])

# Verifikasi ulang jumlah outlier setelah penanganan
print("\nJumlah outlier per kolom setelah penanganan:")
outliers_after_treatment = {}
for col in outlier_cols_check:
    outliers = detect_outliers_iqr(df_no_outlier, col)
    outliers_after_treatment[col] = len(outliers)
    print(f"Jumlah outlier pada kolom '{col}': {len(outliers)}")

# Visualisasi boxplot setelah penanganan
plt.figure(figsize=(15, 10))
for i, col in enumerate(outlier_cols_check):
    plt.subplot(3, 3, i + 1)
    sns.boxplot(y=df_no_outlier[col], color='lightgreen')
    plt.title(f'Boxplot {col} (Setelah Penanganan Outlier)')
    plt.ylabel(col)

plt.tight_layout()
plt.show()

5. MODEL DASAR LOGISTIC REGRESSION
from sklearn.linear_model import LogisticRegression

# Bangun model Logistic Regression dasar
lr_base = LogisticRegression(random_state=42, max_iter=1000)
lr_base.fit(X_train_balanced, y_train_balanced)

# Prediksi
y_pred_base = lr_base.predict(X_test_scaled)
from sklearn.metrics import accuracy_score

# Lakukan prediksi terlebih dahulu (jika belum)
y_pred_base = lr_base.predict(X_test_scaled)

# Evaluasi model
print("EVALUASI MODEL DASAR:")
accuracy_base = accuracy_score(y_test, y_pred_base)
print(f"Akurasi: {accuracy_base:.2f}")

from sklearn.metrics import confusion_matrix

# Hitung confusion matrix
cm_base = confusion_matrix(y_test, y_pred_base)

print("\nConfusion Matrix:")
print(cm_base)

from sklearn.metrics import classification_report

print("\nClassification Report:")

# Dapatkan dan cetak classification report
report_base = classification_report(y_test, y_pred_base, output_dict=True)
print(classification_report(y_test, y_pred_base, target_names=["Tidak Sakit", "Sakit"]))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)

sns.heatmap(cm_base, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Tidak Sakit', 'Sakit'],
            yticklabels=['Tidak Sakit', 'Sakit'])

plt.title('Confusion Matrix - Model Dasar')
plt.ylabel('Aktual')
plt.xlabel('Prediksi')
plt.tight_layout()
plt.show()

# Hitung nilai tn, fp, fn, tp dari confusion matrix
tn, fp, fn, tp = cm_base.ravel()

# Hitung metrik manual sesuai rumus
accuracy_manual = (tp + tn) / (tp + fp + fn + tn)
precision_manual = tp / (tp + fp) if (tp + fp) > 0 else 0
recall_manual = tp / (tp + fn) if (tp + fn) > 0 else 0
f1_manual = 2 * (recall_manual * precision_manual) / (recall_manual + precision_manual) if (recall_manual + precision_manual) > 0 else 0

# Cetak hasil
print(f"\nMetrik Manual (berdasarkan rumus jurnal):")
print(f"True Positive (tp): {tp}")
print(f"True Negative (tn): {tn}")
print(f"False Positive (fp): {fp}")
print(f"False Negative (fn): {fn}")
print(f"Akurasi: {accuracy_manual:.2f} ({accuracy_manual*100:.0f}%)")
print(f"Presisi: {precision_manual:.2f} ({precision_manual*100:.0f}%)")
print(f"Recall: {recall_manual:.2f} ({recall_manual*100:.0f}%)")
print(f"F1-Score: {f1_manual:.2f} ({f1_manual*100:.0f}%)")

6. HYPERPARAMETER TUNING DENGAN GRID SEARCH
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Parameter grid yang diuji
param_grid = {
    'penalty': ['l1', 'l2'],
    'C': [0.1, 0.5, 0.6158, 1.0, 1.5, 2.0, 5.0, 10.0]
}

print("Parameter grid untuk Grid Search:")
print(f"Penalty: {param_grid['penalty']}")
print(f"C values: {param_grid['C']}")

# Grid Search dengan Cross Validation (5-fold)
print("\nMelakukan Grid Search...")

grid_search = GridSearchCV(
    LogisticRegression(random_state=42, max_iter=1000, solver='liblinear'),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=0
)

# Latih model dengan data training yang sudah di-SMOTE
grid_search.fit(X_train_balanced, y_train_balanced)


7. MODEL TERBAIK SETELAH HYPERPARAMETER TUNING
print("✓ Grid Search selesai")
print(f"Parameter terbaik: {grid_search.best_params_}")
print(f"Skor CV terbaik: {grid_search.best_score_:.4f}")
# Ambil model terbaik dari Grid Search
lr_best = grid_search.best_estimator_

# Lakukan prediksi pada data uji (yang sudah dinormalisasi)
y_pred_best = lr_best.predict(X_test_scaled)

# Evaluasi model terbaik
print("EVALUASI MODEL TERBAIK:")
accuracy_best = accuracy_score(y_test, y_pred_best)
print(f"Akurasi: {accuracy_best:.2f}")
# Confusion Matrix model terbaik
cm_best = confusion_matrix(y_test, y_pred_best)
print("\nConfusion Matrix:")
print(cm_best)
print("\nClassification Report:")
report_best = classification_report(y_test, y_pred_best, output_dict=True)
print(classification_report(y_test, y_pred_best))
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 5))

# Visualisasi Confusion Matrix - Model Terbaik
plt.subplot(1, 2, 2)
sns.heatmap(cm_best, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Tidak Sakit', 'Sakit'],
            yticklabels=['Tidak Sakit', 'Sakit'])

plt.title('Confusion Matrix - Model Terbaik')
plt.ylabel('Aktual')
plt.xlabel('Prediksi')
plt.tight_layout()
plt.show()

# Ambil nilai dari confusion matrix model terbaik
tn_best, fp_best, fn_best, tp_best = cm_best.ravel()

# Hitung metrik manual
accuracy_best_manual = (tp_best + tn_best) / (tp_best + fp_best + fn_best + tn_best)
precision_best_manual = tp_best / (tp_best + fp_best) if (tp_best + fp_best) > 0 else 0
recall_best_manual = tp_best / (tp_best + fn_best) if (tp_best + fn_best) > 0 else 0
f1_best_manual = 2 * (recall_best_manual * precision_best_manual) / (recall_best_manual + precision_best_manual) if (recall_best_manual + precision_best_manual) > 0 else 0

# Tampilkan hasil metrik manual
print(f"\nMetrik Manual Model Terbaik:")
print(f"True Positive (tp): {tp_best}")
print(f"True Negative (tn): {tn_best}")
print(f"False Positive (fp): {fp_best}")
print(f"False Negative (fn): {fn_best}")
print(f"Akurasi: {accuracy_best_manual:.2f} ({accuracy_best_manual*100:.0f}%)")
print(f"Presisi: {precision_best_manual:.2f} ({precision_best_manual*100:.0f}%)")
print(f"Recall: {recall_best_manual:.2f} ({recall_best_manual*100:.0f}%)")
print(f"F1-Score: {f1_best_manual:.2f} ({f1_best_manual*100:.0f}%)")

8. PERBANDINGAN KINERJA MODEL
import pandas as pd

# Buat dataframe perbandingan
comparison_data = {
    'Metrik': ['Akurasi', 'Presisi', 'Recall', 'F1-Score'],
    'Model Dasar': [
        accuracy_manual,
        precision_manual,
        recall_manual,
        f1_manual
    ],
    'Model Grid Search': [
        accuracy_best_manual,
        precision_best_manual,
        recall_best_manual,
        f1_best_manual
    ]
}

comparison_df = pd.DataFrame(comparison_data)
comparison_df['Peningkatan'] = comparison_df['Model Grid Search'] - comparison_df['Model Dasar']

# Tampilkan hasil
print("PERBANDINGAN KINERJA:")
print(comparison_df.round(4))

import numpy as np
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
x = np.arange(len(comparison_df['Metrik']))
width = 0.35

# Bar chart untuk Model Dasar dan Model Grid Search
plt.bar(x - width/2, comparison_df['Model Dasar'], width,
        label='Model Dasar', alpha=0.8, color='skyblue')
plt.bar(x + width/2, comparison_df['Model Grid Search'], width,
        label='Model Grid Search', alpha=0.8, color='lightgreen')

# Label sumbu dan judul
plt.xlabel('Metrik Evaluasi')
plt.ylabel('Nilai')
plt.title('Perbandingan Kinerja Model Dasar vs Model Grid Search')
plt.xticks(x, comparison_df['Metrik'])
plt.ylim(0, 1)
plt.legend()

# Tambahkan nilai angka di atas bar
for i, (base, best) in enumerate(zip(comparison_df['Model Dasar'], comparison_df['Model Grid Search'])):
    plt.text(i - width/2, base + 0.01, f'{base:.2f}', ha='center', va='bottom')
    plt.text(i + width/2, best + 0.01, f'{best:.2f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

target_counts = df['target'].value_counts()
target_percent = df['target'].value_counts(normalize=True) * 100

print("\nDistribusi Kelas Target:")
for val in target_counts.index:
    print(f"{val} - {'Sakit Jantung' if val == 1 else 'Tidak Sakit'}: {target_counts[val]} ({target_percent[val]:.2f}%)")

# Visualisasi bar
sns.countplot(x='target', data=df, palette='Set2')
plt.title('Distribusi Kelas Target')
plt.xticks([0, 1], ['Tidak Sakit', 'Sakit'])
plt.ylabel('Jumlah')
plt.show()

# Korelasi kuat terhadap target
corr_target = df.corr()['target'].sort_values(ascending=False)
print("\nKorelasi Fitur terhadap Target (Sakit Jantung):")
print(corr_target)

# Insight awal (manual)
print("\nInsight Awal:")
print("- Pasien dengan nilai 'thalach' tinggi cenderung lebih sehat (berkorelasi negatif dengan target).")
print("- Fitur 'cp' (chest pain), 'slope', dan 'thal' memiliki korelasi positif signifikan terhadap target.")
print("- Dataset relatif seimbang antara pasien sakit dan tidak sakit.")
